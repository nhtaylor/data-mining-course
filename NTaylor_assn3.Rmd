---
title: "GR4058 Data Mining Assignment #3"
author: "Nathan Taylor"
date: "Monday, October 23, 2017"
output: 
  html_document:
    keep_md: true
    toc: true
    toc_float: true
    theme: yeti
    highlight: tango
    df_print: paged
editor_options: 
  chunk_output_type: console
---

```{r, results = 'hide', message = FALSE, warning = FALSE}
## PACKAGES & LIBRARIES
library(tm)
library(SnowballC)
library(topicmodels)
library(Matrix)
```

## 1. Principal Components Analysis
**Prompt: In this problem, we are going to do a Principal Components Analysis (PCA) “manually” without the aid of the prcomp() function.**

```{r}
# reading in data
set.seed(12345)
X <- as.matrix(read.csv("dataset3.csv"))

# scaling variables
Z <- scale(X)

# perform singular value decomposition
Z_svd <- svd(Z)
sdev <- Z_svd$d / sqrt(nrow(Z) - 1)
sdev


# truncate to preserve 95% of variances
cv <- round(cumsum(sdev^2) / crossprod(sdev)[1], digits = 3)
cv
K <- which(cv > 0.95)[1]
K

# creating the plane, with at least two components
K <- 2
Y <- Z_svd$u[, 1:K, drop = FALSE] %*% diag(sdev[1:K], nrow = K, ncol = K)

# creating plot
library(ggplot2)
ggplot(as.data.frame(Y)) + 
  geom_point(aes(x = V1, y = V2))

## doing PCA in robust manner to see difference
library(pcaPP) 
par(mar = rep(2, times = 4) + .1, las = 1, cex = 0.7)
biplot(PCAproj(X, k = 2, scale = sd))
```


## 2. Clustering
**Prompt: Using the same original dataset as in the first problem, perform a K-means clustering with a “reasonable” number of clusters. Show how you arrived at this number of clusters. Which observations fell into which cluster?**

```{r}
km_X <- kmeans(X, centers = 2)
km_X
plot(X, col = km_X$cluster + 1, pch = 20, cex = 1,
     main="K-Means Clustering Results for X with K=2", xlab = "", ylab = "")

km_X1 <- kmeans(X, centers = 3)
km_X1
plot(X, col = km_X1$cluster + 1, pch = 20, cex = 1,
     main="K-Means Clustering Results for X with K=3", xlab = "", ylab = "")

km_X2 <- kmeans(X, centers = 4)
km_X2
plot(X, col = km_X2$cluster + 1, pch = 20, cex = 1,
     main = "K-Means Clustering Results for X with K=4", xlab = "", ylab = "")

km_X3 <- kmeans(X, centers = 5)
km_X3
plot(X, col = km_X3$cluster + 1, pch = 20, cex = 1,
     main = "K-Means Clustering Results for X with K=5", xlab = "", ylab = "")
```

I decided that, overall, five distinct clusters would represent the data well. It's best, I think, to help visualize the plots in order to see the data. My main concern was that the outliers on both ends of the data would  negatively influence the structure within each cluster. I decided to plot clusters K = 2 through K = 5 just to explore what might appear best. It's possible that going with four or fewer clusters might be more advantages because the middling points are more likely to be clustered together, but there would be advantages and disadvantages to any decsion. The following R output should show which observations fell into which cluster:

```{r}
km_X3$cluster
```

## 3. Text Mining
**Prompt: (A) Use the functions in the tm package to create an appropriate DocumentTermMatrix for this corpus. (B) Use the LDA function in the topicmodels package to perform Latent Dirichlet Allocation across k = 3 clusters. (C) Based on your reading of a few important speeches, what topics do each of these three clusters represent?**


```{r}
unzip("Speeches_May_1967.zip")
dir("Speeches_May_1967")

speeches <- Corpus(DirSource(directory = "Speeches_May_1967"))
speeches

## cleaning up speeches for the dtm
speeches <- tm_map(speeches, content_transformer(tolower))
speeches <- tm_map(speeches, stripWhitespace) 
speeches <- tm_map(speeches, removePunctuation)
speeches <- tm_map(speeches, removeNumbers)
speeches <- tm_map(speeches, removeWords, stopwords("english"))
speeches <- tm_map(speeches, stemDocument)

speech.dtm <- DocumentTermMatrix(speeches)
speech.dtm
## colnames(speech.dtm)

speech.clust <- LDA(weightTf(speech.dtm), k = 3)
round.clust <- round(posterior(speech.clust, speech.dtm)$topics, digits = 3)
round.clust
```

AFter examining the first two speeches in the first cluster that had a 
probability of 1.00 (speeches 02 and 06), this cluster appears to most closely
be concerned with policies related to education, job training, and labor 
practices. The second cluster, represented by speeches 04 and 07, focuses 
primarily on programs related to military matters or service to one's country 
(Selective Service, Universal Military Training and Service Act, etc.). 
Finally, the last cluster of texts emphasizes economic matters both in the 
domestic and foreign policy spheres.
